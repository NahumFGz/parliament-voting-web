IMAGE_CSV_PATH = "./encabezados.csv"
OUTPUT_DIR = "./api_outputs"


MODEL = "gpt-5-mini"
PROMPT = "EN BASE AL TEXTO DE LA IMAGEN DEVUELVE √öNICAMENTE UN JSON CON LAS LLAVES: 'tipo' (ASISTENCIA O VOTACI√ìN), 'fecha', 'hora', 'asunto'; SI ALG√öN VALOR NO SE IDENTIFICA PON 'null'; TODO EL CONTENIDO DEBE IR EN MAY√öSCULAS; NO AGREGUES COMENTARIOS NI TEXTO ADICIONAL."

NUM_WORKERS = 16  # N√∫mero de hilos para procesamiento paralelo
MAX_RETRIES = 3  # N√∫mero m√°ximo de reintentos por imagen
RETRY_DELAY_BASE = 5  # Segundos de espera base entre reintentos (se multiplica exponencialmente)

import os
import time
from concurrent.futures import ThreadPoolExecutor, as_completed
from threading import Lock

import pandas as pd
from utils_openai_ocr import process_image_ocr

# Lock para escritura segura en consola
print_lock = Lock()


def safe_print(message):
    """Imprime de forma segura en entorno multi-thread"""
    with print_lock:
        print(message)


def procesar_imagen(row_data, idx, total):
    """
    Procesa una imagen individual con reintentos

    Args:
        row_data: dict con la informaci√≥n de la fila (file_name, json_name, image_path)
        idx: √≠ndice actual
        total: total de im√°genes a procesar

    Returns:
        tuple: (success: bool, file_name: str, error_msg: str or None)
    """
    file_name = row_data["file_name"]
    image_path = row_data["image_path"]
    json_name = row_data["json_name"]

    # Construir la ruta de salida
    output_path = os.path.join(OUTPUT_DIR, json_name)

    # Verificar que la imagen existe
    if not os.path.exists(image_path):
        safe_print(f"[{idx}/{total}] SALTADO - No existe: {image_path}")
        return (False, file_name, "Archivo no existe")

    # Intentar procesar con reintentos
    for intento in range(1, MAX_RETRIES + 1):
        try:
            safe_print(f"[{idx}/{total}] Procesando: {file_name} (intento {intento}/{MAX_RETRIES})")

            result = process_image_ocr(
                image_path=image_path,
                resize_percent=100,
                model=MODEL,
                max_tokens=2500,
                prompt=PROMPT,
                output_path=output_path,
            )

            safe_print(f"[{idx}/{total}] ‚úì {file_name} - Guardado exitosamente")
            return (True, file_name, None)

        except Exception as e:
            error_msg = str(e)
            if intento < MAX_RETRIES:
                delay = RETRY_DELAY_BASE * (2 ** (intento - 1))  # Backoff exponencial: 5s, 10s, 20s
                safe_print(
                    f"[{idx}/{total}] ‚ö† {file_name} - Error (reintentando en {delay}s): {error_msg}"
                )
                time.sleep(delay)
            else:
                safe_print(
                    f"[{idx}/{total}] ‚úó {file_name} - Error final despu√©s de {MAX_RETRIES} intentos: {error_msg}"
                )
                return (False, file_name, error_msg)

    return (False, file_name, "N√∫mero m√°ximo de reintentos alcanzado")


# Crear directorio de salida si no existe
os.makedirs(OUTPUT_DIR, exist_ok=True)

# Leer el CSV
df = pd.read_csv(IMAGE_CSV_PATH)

# Obtener lista de archivos JSON ya procesados
archivos_procesados = set()
if os.path.exists(OUTPUT_DIR):
    for archivo in os.listdir(OUTPUT_DIR):
        if archivo.endswith(".json"):
            archivos_procesados.add(archivo)

print("\n" + "=" * 60)
print("üìä ESTADO DEL PROCESAMIENTO")
print("=" * 60)
print(f"üìÅ Total de im√°genes en CSV: {len(df)}")
print(f"‚úÖ Ya procesadas correctamente (se omitir√°n): {len(archivos_procesados)}")

# Filtrar el DataFrame para excluir los ya procesados
df_filtrado = df[~df["json_name"].isin(archivos_procesados)]

print(f"üîÑ Pendientes por procesar: {len(df_filtrado)}")
print(f"‚öôÔ∏è  Trabajadores paralelos: {NUM_WORKERS}")
print(f"üîÅ Reintentos m√°ximos por imagen: {MAX_RETRIES}")
print(f"‚è±Ô∏è  Delay base entre reintentos: {RETRY_DELAY_BASE}s")

if len(archivos_procesados) > 0:
    porcentaje_completado = (len(archivos_procesados) / len(df)) * 100
    print(f"üìà Progreso total: {porcentaje_completado:.1f}% completado")

print("=" * 60)

# Verificar si hay algo que procesar
if len(df_filtrado) == 0:
    print("\n‚ú® ¬°Todo est√° procesado! No hay im√°genes pendientes.\n")
    exit(0)

# Preparar datos para procesamiento paralelo
tareas = []
for idx, (index, row) in enumerate(df_filtrado.iterrows(), 1):
    row_data = {
        "file_name": row["file_name"],
        "json_name": row["json_name"],
        "image_path": row["image_path"],
    }
    tareas.append((row_data, idx, len(df_filtrado)))

# Procesar en paralelo con ThreadPoolExecutor
start_time = time.time()
exitosos = 0
fallidos = 0
errores = []

print(f"\nüöÄ Iniciando procesamiento paralelo...\n")

with ThreadPoolExecutor(max_workers=NUM_WORKERS) as executor:
    # Enviar todas las tareas
    futures = {executor.submit(procesar_imagen, *tarea): tarea for tarea in tareas}

    # Procesar resultados conforme se completan
    for future in as_completed(futures):
        try:
            success, file_name, error_msg = future.result()
            if success:
                exitosos += 1
            else:
                fallidos += 1
                if error_msg:
                    errores.append((file_name, error_msg))
        except Exception as e:
            fallidos += 1
            safe_print(f"‚úó Error inesperado en thread: {str(e)}")

# Resumen final
elapsed_time = time.time() - start_time
total_procesados = exitosos + fallidos

print("\n" + "=" * 60)
print("RESUMEN DE PROCESAMIENTO")
print("=" * 60)
print(f"Total procesados: {total_procesados}")
print(f"‚úì Exitosos: {exitosos}")
print(f"‚úó Fallidos: {fallidos}")
print(f"‚è± Tiempo total: {elapsed_time:.2f} segundos")
if total_procesados > 0:
    print(f"‚ö° Promedio: {elapsed_time/total_procesados:.2f} seg/imagen")
print("=" * 60)

# Mostrar errores si hay
if errores:
    print("\nERRORES ENCONTRADOS:")
    print("-" * 60)
    for file_name, error_msg in errores[:10]:  # Mostrar m√°ximo 10 errores
        print(f"  ‚Ä¢ {file_name}: {error_msg}")
    if len(errores) > 10:
        print(f"  ... y {len(errores) - 10} errores m√°s")
    print("-" * 60)
